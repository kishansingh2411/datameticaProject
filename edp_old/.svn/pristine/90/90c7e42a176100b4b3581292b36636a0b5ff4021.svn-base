#!/bin/sh

######################################################################################################################
#   This source code is the property of:
#   Cablevision Systems Corporation, Inc. (c) 2015
#   1111 Stewart Avenue, Bethpage, NY 11714
#   www.cablevision.com
#   Department: AM
#
#   Program name: compute_statistics.sh
#   Program type: Unix Bash Shell script
#   Purpose:    : This will load data in all gold tables.
#                 Input Arguments for this script are: "key_param_id" "table_name"           
#   Author(s)   : DataMetica Team
#   Usage       : compute_statistics.sh "key_param_id" "table_name"
#   Date        : 04/12/2016
#   Log File    : .../log/mrdvr/${job_name}.log
#   SQL File    : 
#   Error File  : .../log/mrdvr/${job_name}.log
#   Dependency  : 
#   Disclaimer  : 
#
#   Modification History :
#   =======================
#
#    ver     who                      date             comments
#   ------   --------------------     ----------       -------------------------------------
#    1.0     DataMetica Team          10/20/2016       Initial version
#
#
#####################################################################################################################

###############################################################################
#                          Module Environment Setup                           #
###############################################################################

# Find absolute path to this script which is used to define module, project, subject area home directory paths.
pushd . > /dev/null
SCRIPT_HOME="${BASH_SOURCE[0]}";
while([ -h "${SCRIPT_HOME}" ]); do
    cd "`dirname "${SCRIPT_HOME}"`"
    SCRIPT_HOME="$(readlink "`basename "${SCRIPT_HOME}"`")";
done
cd "`dirname "${SCRIPT_HOME}"`" > /dev/null
SCRIPT_HOME="`pwd`";
popd  > /dev/null

# Set module, project, subject area home paths.
SUBJECT_AREA_HOME=`dirname ${SCRIPT_HOME}`
SUBJECT_AREAS_HOME=`dirname ${SUBJECT_AREA_HOME}`
HOME=`dirname ${SUBJECT_AREAS_HOME}`

###                                                                           
# Load all environment properties files
source $HOME/etc/namespace.properties
source $HOME/etc/beeline.properties
source $HOME/etc/default.env.properties
source $HOME/etc/postgres.properties
source $SUBJECT_AREA_HOME/etc/subject-area.env.properties
source $SUBJECT_AREA_HOME/etc/mrdvr.properties
source $SUBJECT_AREA_HOME/etc/mysql.properties

source $HOME/bin/functions.sh
source $SUBJECT_AREA_HOME/bin/mrdvr_functions.sh

##############################################################################
#                                                                            #
# Checking number of parameter passed                                        #
#                                                                            #
##############################################################################

if [ "$#" -ne 2 ] 
then
   echo "Illegal number of parameters. Parameters expected are [ "key_param_id" "table_name" ]"
   exit -1
fi

##############################################################################
#																			 #
# Local Params				 								 	 			 #
#																			 #
##############################################################################

key_param_id="$1"
table_name="$(echo "$2" | tr '[:upper:]' '[:lower:]')"

if [[ $table_name == "rsdvr_preferences" ]]
then
    job_name="EDP_MRDVR_600006_COMP_STAT_PRF"
elif [[ $table_name == "rsdvr_recordings_archive" ]]
then
    job_name="EDP_MRDVR_600006_COMP_STAT_RCA"
elif [[ $table_name == "rsdvr_recordings" ]]
then
    job_name="EDP_MRDVR_600006_COMP_STAT_REC"
elif [[ $table_name == "rsdvr_requests_archive" ]]
then
    job_name="EDP_MRDVR_600006_COMP_STAT_RQA"
elif [[ $table_name == "rsdvr_requests" ]]
then
    job_name="EDP_MRDVR_600006_COMP_STAT_REQ"
elif [[ $table_name == "rsdvr_schedule" ]]
then
    job_name="EDP_MRDVR_600006_COMP_STAT_SCH"
else
    echo "Wrong table name provided"
    exit -1
fi

params="$(fn_get_mrdvr_params ${key_param_id})"

if [ -z "$params" ]
then
    echo "Invalid Key-Param Id found : $key_param_id" 
    exit -1
fi

source_date=$(echo $params | cut -d'~' -f1)
start_time=`date +"%Y-%m-%d %H:%M:%S"`
fn_get_current_batch_id
log_file_path="${LOG_DIR}/${SUBJECT_AREA_NAME}/${job_name}.log"

##############################################################################
#																			 #
# Capture statistics                                                         #
#																			 #
##############################################################################

fn_insert_job_statistics "${BATCH_ID}" "${job_name}" "${start_time}" "RUNNING" "${log_file_path}" 

##############################################################################
#																			 #
# Compute Insert Records Count                                               #
#																			 #
##############################################################################

insert_rec_cnt="$(fn_get_count "${HIVESERVER2_URL}" "${HIVE_USENAME}" "${HIVE_PASSWORD}" "${HIVE_DATABASE_NAME_GOLD}" "gold_${table_name}_last_rec" "I" "${source_date}")"
exit_code=$?

if [ ${exit_code} -ne ${EXIT_CODE_SUCCESS} ]
  then
     fn_log_error "Failed while computing insert record count for table ${table_name} " "${log_file_path}"
     fn_update_job_statistics "${BATCH_ID}" "${job_name}" "${start_time}" "0" "${exit_code}" "${source_date}" "${log_file_path}" "" " "
  fi
 
fn_log_info "Successfully computed insert record count for table ${table_name} " "${log_file_path}"

##############################################################################
#																			 #
# Compute Update Records Count                                               #
#																			 #
##############################################################################

update_rec_cnt="$(fn_get_count "${HIVESERVER2_URL}" "${HIVE_USENAME}" "${HIVE_PASSWORD}" "${HIVE_DATABASE_NAME_GOLD}" "gold_${table_name}_last_rec" "U" "${source_date}")"
exit_code=$?

if [ ${exit_code} -ne ${EXIT_CODE_SUCCESS} ]
  then
     fn_log_error "Failed while computing update record count for table ${table_name} " "${log_file_path}"
     fn_update_job_statistics "${BATCH_ID}" "${job_name}" "${start_time}" "0" "${exit_code}" "${source_date}" "${log_file_path}" "" " "
  fi
 
fn_log_info "Successfully computed update record count for table ${table_name} " "${log_file_path}"

##############################################################################
#																			 #
# Compute Delete Records Count                                               #
#																			 #
##############################################################################

delete_rec_cnt="$(fn_get_count "${HIVESERVER2_URL}" "${HIVE_USENAME}" "${HIVE_PASSWORD}" "${HIVE_DATABASE_NAME_GOLD}" "gold_${table_name}_last_rec" "D" "${source_date}")"
exit_code=$?

if [ ${exit_code} -ne ${EXIT_CODE_SUCCESS} ]
  then
     fn_log_error "Failed while computing delete record count for table ${table_name} " "${log_file_path}"
     fn_update_job_statistics "${BATCH_ID}" "${job_name}" "${start_time}" "0" "${exit_code}" "${source_date}" "${log_file_path}" "" " "
  fi
 
fn_log_info "Successfully computed delete record count for table ${table_name} " "${log_file_path}"

##############################################################################
#																			 #
# Compute Dedup Records Count                                                #
#																			 #
##############################################################################

seq_rec_cnt="$(fn_get_count "${HIVESERVER2_URL}" "${HIVE_USENAME}" "${HIVE_PASSWORD}" "${HIVE_DATABASE_NAME_WORK}" "work_${table_name}_seq" "DD" "${source_date}")"

if [ ${exit_code} -ne ${EXIT_CODE_SUCCESS} ]
then
     fn_log_error "Failed while computing seq record count for table ${table_name} " "${log_file_path}"
     fn_update_job_statistics "${BATCH_ID}" "${job_name}" "${start_time}" "0" "${exit_code}" "${source_date}" "${log_file_path}" "" " "
fi
 
fn_log_info "Successfully computed seq record count for table ${table_name} " "${log_file_path}"

dedup_rec_cnt="$(fn_get_count "${HIVESERVER2_URL}" "${HIVE_USENAME}" "${HIVE_PASSWORD}" "${HIVE_DATABASE_NAME_WORK}" "work_${table_name}_dedup" "DD" "${source_date}")"
exit_code=$?

if [ ${exit_code} -ne ${EXIT_CODE_SUCCESS} ]
then
     fn_log_error "Failed while computing dedup record count for table ${table_name} " "${log_file_path}"
     fn_update_job_statistics "${BATCH_ID}" "${job_name}" "${start_time}" "0" "${exit_code}" "${source_date}" "${log_file_path}" "" " "
fi
 
fn_log_info "Successfully computed dedup record count for table ${table_name} " "${log_file_path}"

final_dedup_rec_cnt=$(expr "$seq_rec_cnt" - "$dedup_rec_cnt")

##############################################################################
#																			 #
# Compute Duplicate Records Count  between incoming and work                  #
#																			 #
##############################################################################

incoming_rec_cnt="$(fn_get_hive_count "${HIVESERVER2_URL}" "${HIVE_USENAME}" "${HIVE_PASSWORD}" "${HIVE_DATABASE_NAME_INCOMING}" "INCOMING_${table_name}" "" "${source_date}")"

if [ ${exit_code} -ne ${EXIT_CODE_SUCCESS} ]
then
     fn_log_error "Failed while computing record count for table ${table_name} " "${log_file_path}"
     fn_update_job_statistics "${BATCH_ID}" "${job_name}" "${start_time}" "0" "${exit_code}" "${source_date}" "${log_file_path}" "" " "
fi

fn_log_info "Successfully computed incoming record count for table ${table_name} " "${log_file_path}"

work_rec_cnt="$(fn_get_count "${HIVESERVER2_URL}" "${HIVE_USENAME}" "${HIVE_PASSWORD}" "${HIVE_DATABASE_NAME_WORK}" "work_${table_name}" "TOTAL" "${source_date}")"

if [ ${exit_code} -ne ${EXIT_CODE_SUCCESS} ]
then
     fn_log_error "Failed while computing record count for table ${table_name} " "${log_file_path}"
     fn_update_job_statistics "${BATCH_ID}" "${job_name}" "${start_time}" "0" "${exit_code}" "${source_date}" "${log_file_path}" "" " "
fi

fn_log_info "Successfully computed work record count for table ${table_name} " "${log_file_path}"

duplicate_rec_cnt=$(expr "$work_rec_cnt" - "$incoming_rec_cnt")

##############################################################################
#																			 #
# Compute Total Records Count                                                #
#																			 #
##############################################################################

total_rec_cnt="$(fn_get_count "${HIVESERVER2_URL}" "${HIVE_USENAME}" "${HIVE_PASSWORD}" "${HIVE_DATABASE_NAME_WORK}" "work_${table_name}" "TOTAL" "${source_date}")"
exit_code=$?

if [ ${exit_code} -ne ${EXIT_CODE_SUCCESS} ]
then
	fn_log_error "Failed while computing total record count for table ${table_name} " "${log_file_path}"
	fn_update_job_statistics "${BATCH_ID}" "${job_name}" "${start_time}" "0" "${exit_code}" "${source_date}" "${log_file_path}" "" " "
fi 
 
fn_log_info "Successfully computed total record count for table ${table_name} " "${log_file_path}"

##############################################################################
#																			 #
# Insert statistics into Postgres                                            #
#																			 #
##############################################################################

fn_insert_cdc_process "${SUBJECT_AREA_NAME}" "${table_name}" "${source_date}" "${duplicate_rec_cnt}" "${final_dedup_rec_cnt}" "${insert_rec_cnt}" "${update_rec_cnt}" "${delete_rec_cnt}" "${total_rec_cnt}" "${log_file_path}" 

##############################################################################
#                                                                            #
# Capture statistics                                                         #
#                                                                            #
##############################################################################

fn_update_job_statistics "${BATCH_ID}" "${job_name}" "${start_time}" "${hive_counts}" "${exit_code}" "${source_date}" "${log_file_path}" "" " "

##############################################################################
#                                    End                                     #
##############################################################################